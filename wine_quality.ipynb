{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bita1828b5594684926a6374e23c22bc525",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\n- Random Forest with GridSearchCV\\n- Python Pandas External Dataset Machine Learning Classifers Grid Search CV Optimizing Parameters \\n\\nThe following dataset has information around red wine characteristics (acidity, pH, etc) as well as a quality rating. More information about the schema can be found here.\\nGiven this, create a Random Forest model to predict wine quality. Additionally, use GridSearchCV (or a tool of your own choice) to find the best parameters for the model.\\n\\ndataset: https://raw.githubusercontent.com/erood/interviewqs.com_code_snippets/master/Datasets/winequality-red.csv\\ninformation about dataset: https://archive.ics.uci.edu/ml/datasets/Wine+Quality\\ninformation about gridsearch: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\\nreference: https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/\\n\\nPS: First, I imported the dataset to excel in order to normalize the data and overwritten the dataset file.\\n'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "'''\n",
    "- Random Forest with GridSearchCV\n",
    "- Python Pandas External Dataset Machine Learning Classifers Grid Search CV Optimizing Parameters \n",
    "\n",
    "The following dataset has information around red wine characteristics (acidity, pH, etc) as well as a quality rating. More information about the schema can be found here.\n",
    "Given this, create a Random Forest model to predict wine quality. Additionally, use GridSearchCV (or a tool of your own choice) to find the best parameters for the model.\n",
    "\n",
    "dataset: https://raw.githubusercontent.com/erood/interviewqs.com_code_snippets/master/Datasets/winequality-red.csv\n",
    "information about dataset: https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "information about gridsearch: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to use in the project\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.4              0.70         0.00             1.9      0.076   \n1            7.8              0.88         0.00             2.6      0.098   \n2            7.8              0.76         0.04             2.3      0.092   \n3           11.2              0.28         0.56             1.9      0.075   \n4            7.4              0.70         0.00             1.9      0.076   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 11.0                  34.0   0.9978  3.51       0.56   \n1                 25.0                  67.0   0.9968  3.20       0.68   \n2                 15.0                  54.0   0.9970  3.26       0.65   \n3                 17.0                  60.0   0.9980  3.16       0.58   \n4                 11.0                  34.0   0.9978  3.51       0.56   \n\n   alcohol  quality  \n0      9.4        5  \n1      9.8        5  \n2      9.8        5  \n3      9.8        6  \n4      9.4        5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.9968</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.9970</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.9980</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Importing dataset and Analysing the data\n",
    "dataset = pd.read_csv('wine_quality-red.csv', sep=';')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1599, 12)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Checking the shape of the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\ncount    1599.000000       1599.000000  1599.000000     1599.000000   \nmean        8.319637          0.527821     0.270976        2.538806   \nstd         1.741096          0.179060     0.194801        1.409928   \nmin         4.600000          0.120000     0.000000        0.900000   \n25%         7.100000          0.390000     0.090000        1.900000   \n50%         7.900000          0.520000     0.260000        2.200000   \n75%         9.200000          0.640000     0.420000        2.600000   \nmax        15.900000          1.580000     1.000000       15.500000   \n\n         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\ncount  1599.000000          1599.000000           1599.000000  1599.000000   \nmean      0.087467            15.874922             46.467792     0.996747   \nstd       0.047065            10.460157             32.895324     0.001887   \nmin       0.012000             1.000000              6.000000     0.990070   \n25%       0.070000             7.000000             22.000000     0.995600   \n50%       0.079000            14.000000             38.000000     0.996750   \n75%       0.090000            21.000000             62.000000     0.997835   \nmax       0.611000            72.000000            289.000000     1.003690   \n\n                pH    sulphates      alcohol      quality  \ncount  1599.000000  1599.000000  1599.000000  1599.000000  \nmean      3.311113     0.658149    10.422983     5.636023  \nstd       0.154386     0.169507     1.065668     0.807569  \nmin       2.740000     0.330000     8.400000     3.000000  \n25%       3.210000     0.550000     9.500000     5.000000  \n50%       3.310000     0.620000    10.200000     6.000000  \n75%       3.400000     0.730000    11.100000     6.000000  \nmax       4.010000     2.000000    14.900000     8.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8.319637</td>\n      <td>0.527821</td>\n      <td>0.270976</td>\n      <td>2.538806</td>\n      <td>0.087467</td>\n      <td>15.874922</td>\n      <td>46.467792</td>\n      <td>0.996747</td>\n      <td>3.311113</td>\n      <td>0.658149</td>\n      <td>10.422983</td>\n      <td>5.636023</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.741096</td>\n      <td>0.179060</td>\n      <td>0.194801</td>\n      <td>1.409928</td>\n      <td>0.047065</td>\n      <td>10.460157</td>\n      <td>32.895324</td>\n      <td>0.001887</td>\n      <td>0.154386</td>\n      <td>0.169507</td>\n      <td>1.065668</td>\n      <td>0.807569</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.600000</td>\n      <td>0.120000</td>\n      <td>0.000000</td>\n      <td>0.900000</td>\n      <td>0.012000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>0.990070</td>\n      <td>2.740000</td>\n      <td>0.330000</td>\n      <td>8.400000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7.100000</td>\n      <td>0.390000</td>\n      <td>0.090000</td>\n      <td>1.900000</td>\n      <td>0.070000</td>\n      <td>7.000000</td>\n      <td>22.000000</td>\n      <td>0.995600</td>\n      <td>3.210000</td>\n      <td>0.550000</td>\n      <td>9.500000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.900000</td>\n      <td>0.520000</td>\n      <td>0.260000</td>\n      <td>2.200000</td>\n      <td>0.079000</td>\n      <td>14.000000</td>\n      <td>38.000000</td>\n      <td>0.996750</td>\n      <td>3.310000</td>\n      <td>0.620000</td>\n      <td>10.200000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.200000</td>\n      <td>0.640000</td>\n      <td>0.420000</td>\n      <td>2.600000</td>\n      <td>0.090000</td>\n      <td>21.000000</td>\n      <td>62.000000</td>\n      <td>0.997835</td>\n      <td>3.400000</td>\n      <td>0.730000</td>\n      <td>11.100000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.900000</td>\n      <td>1.580000</td>\n      <td>1.000000</td>\n      <td>15.500000</td>\n      <td>0.611000</td>\n      <td>72.000000</td>\n      <td>289.000000</td>\n      <td>1.003690</td>\n      <td>4.010000</td>\n      <td>2.000000</td>\n      <td>14.900000</td>\n      <td>8.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Checking the description of the dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "fixed acidity           float64\nvolatile acidity        float64\ncitric acid             float64\nresidual sugar          float64\nchlorides               float64\nfree sulfur dioxide     float64\ntotal sulfur dioxide    float64\ndensity                 float64\npH                      float64\nsulphates               float64\nalcohol                 float64\nquality                   int64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Checking dataset types\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 7.4    0.7    0.    ...  3.51   0.56   9.4  ]\n [ 7.8    0.88   0.    ...  3.2    0.68   9.8  ]\n [ 7.8    0.76   0.04  ...  3.26   0.65   9.8  ]\n ...\n [ 6.3    0.51   0.13  ...  3.42   0.75  11.   ]\n [ 5.9    0.645  0.12  ...  3.57   0.71  10.2  ]\n [ 6.     0.31   0.47  ...  3.39   0.66  11.   ]]\n"
    }
   ],
   "source": [
    "# Labeling the data\n",
    "# We want to predict wine quality so X will be all columns except quality\n",
    "\n",
    "X_data = dataset.drop('quality', axis=1).values     # all columns except 'quality'\n",
    "print(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[5 5 5 ... 6 5 6]\n"
    }
   ],
   "source": [
    "# Labeling the data\n",
    "\n",
    "y_data = dataset['quality'].values      # just 'quality' column\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of test samples : (240, 11)\nnumber of training samples: (1359, 11)\n"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.15, random_state=0)\n",
    "\n",
    "print(\"number of test samples :\", X_test.shape)\n",
    "print(\"number of training samples:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "BEFORE SCALING:\nX_train:\n[[7.40e+00 6.10e-01 1.00e-02 ... 3.48e+00 6.50e-01 9.80e+00]\n [6.90e+00 7.65e-01 1.80e-01 ... 3.40e+00 6.00e-01 1.03e+01]\n [8.70e+00 6.90e-01 0.00e+00 ... 3.36e+00 4.50e-01 9.40e+00]\n ...\n [7.90e+00 5.70e-01 3.10e-01 ... 3.29e+00 6.90e-01 9.50e+00]\n [1.30e+01 4.70e-01 4.90e-01 ... 3.30e+00 6.80e-01 1.27e+01]\n [9.80e+00 9.80e-01 3.20e-01 ... 3.25e+00 4.80e-01 9.40e+00]]\n\nX_test:\n[[10.8   0.47  0.43 ...  3.17  0.76 10.8 ]\n [ 8.1   0.82  0.   ...  3.36  0.53  9.6 ]\n [ 9.1   0.29  0.33 ...  3.26  0.84 11.7 ]\n ...\n [ 9.2   0.31  0.36 ...  3.33  0.86 12.  ]\n [ 6.8   0.36  0.32 ...  3.36  0.55 12.8 ]\n [10.4   0.52  0.45 ...  3.22  0.76 11.4 ]]\n\nAFTER SCALING:\nX_train:\n[[-0.53574243  0.43487983 -1.33321092 ...  1.10026409 -0.04612167\n  -0.57529378]\n [-0.8253963   1.28248808 -0.46454456 ...  0.58100936 -0.33443511\n  -0.10312066]\n [ 0.21735763  0.87235506 -1.38430894 ...  0.321382   -1.19937545\n  -0.95303227]\n ...\n [-0.24608856  0.21614222  0.19972972 ... -0.13296589  0.18452909\n  -0.85859765]\n [ 2.70838091 -0.33070182  1.1194941  ... -0.06805905  0.1268664\n   2.1633103 ]\n [ 0.85459614  2.45820276  0.25082774 ... -0.39259326 -1.02638738\n  -0.95303227]]\n\nX_test:\n[[ 1.37933275 -0.27703232  0.83861973 ... -0.9284373   0.69681691\n   0.27237078]\n [-0.10465799  1.9888601  -1.43411022 ...  0.29093888 -0.88999388\n  -0.82090845]\n [ 0.44496821 -1.44234843  0.31007789 ... -0.35083806  1.2487511\n   1.0923302 ]\n ...\n [ 0.49993083 -1.31286886  0.46864044 ...  0.0984058   1.38673465\n   1.36565001]\n [-0.81917205 -0.98916994  0.2572237  ...  0.29093888 -0.75201033\n   2.09450283]\n [ 1.15948227  0.04666659  0.9443281  ... -0.60754883  0.69681691\n   0.81901039]]\n"
    }
   ],
   "source": [
    "'''\n",
    "You can check the dataset and see that it is not scaled well since there are columns such as \"fixed acidity\" and \"alcohol\" that have values higher than 0 and 1. In that case, we need to scale those values down to values between 0 and 1.\n",
    "'''\n",
    "print(\"BEFORE SCALING:\")\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "dataset_scaler = StandardScaler()\n",
    "X_train = dataset_scaler.fit_transform(X_train)\n",
    "X_test = dataset_scaler.fit_transform(X_test)\n",
    "print(\"\\nAFTER SCALING:\")\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the dataset using Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=300, random_state=0)\n",
    "# rf.fit(X=X_train, y=y_train)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.66544118 0.63970588 0.66911765 0.70220588 0.70110701]\n"
    }
   ],
   "source": [
    "# Next step is getting accuracy for all folds using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracy = cross_val_score(estimator=rf_classifier, X=X_train, y=y_train, cv=5)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy mean = 67.55%\nStandard deviation = 2.36%\n"
    }
   ],
   "source": [
    "# Checking the average of accuracy\n",
    "\n",
    "print(f'Accuracy mean = {accuracy.mean()*100:.2f}%')\n",
    "print(f'Standard deviation = {accuracy.std()*100:.2f}%')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV to find the best parameters for the model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_parameters = {\n",
    "    'n_estimators': [100, 200, 400, 600, 800, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=grid_parameters, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                              class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              max_samples=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              n_estimators=300, n_jobs=None,\n                                              oob_score=False, random_state=0,\n                                              verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=None,\n             param_grid={'bootstrap': [True, False],\n                         'criterion': ['gini', 'entropy'],\n                         'n_estimators': [100, 200, 400, 600, 800, 1000]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=0)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Fitting the data test set\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameter: {'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 1000}\nBest score: 67.85%\n"
    }
   ],
   "source": [
    "# Checking what is the best parameter and the best score\n",
    "\n",
    "print(f'Best parameter: {grid_search.best_params_}')\n",
    "print(f'Best score: {grid_search.best_score_*100:.2f}%')"
   ]
  }
 ]
}